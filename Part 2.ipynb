{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***PART 1***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from multiprocessing import Process\n",
    "from time import time\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the data and removing unwanted columns specified below\n",
    "df = pd.read_csv('weatherAUS.csv')\n",
    "df = df.drop(df.columns[0],axis = 1)#Dropping the Dates\n",
    "df =df.drop(df.columns[-2], axis = 1)#Dropping the RISK_MM column\n",
    "limitPer = len(df) * .7\n",
    "df_2 = df.dropna(thresh=limitPer,axis=1)\n",
    "data = df_2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Any features with more than 30% of empty data are removed\n",
    "limitPer = len(df_2) * .7\n",
    "df_2 = df_2.dropna(thresh=limitPer,axis=1)\n",
    "df_3 = df_2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performing imputation on missing values\n",
    "#Using Median values to fill up missing numerical features - to avoid taking mean consisting of outliers\n",
    "imp1 = SimpleImputer(strategy=\"median\")\n",
    "df_knn_imputed_float_columns = imp1.fit_transform(df_2[df_2.columns[df_2.dtypes=='float64']])\n",
    "df_knn_imputed_float_columns = pd.DataFrame(df_knn_imputed_float_columns,columns = list(data.columns[data.dtypes=='float64']))\n",
    "\n",
    "#Using most frequent values to fill up missing categorical features - to keep the process simple at this point\n",
    "imp2 = SimpleImputer(strategy=\"most_frequent\")\n",
    "df_knn_imputed_categorical_columns = imp2.fit_transform(df[df.columns[df.dtypes!='float64']])\n",
    "df_knn_imputed_categorical_columns = pd.DataFrame(df_knn_imputed_categorical_columns,columns = list(data.columns[data.dtypes!='float64']))\n",
    "\n",
    "#Combining and arranging the above 2 numerical and categorical dataframes into 1\n",
    "df_new = pd.concat([df_knn_imputed_float_columns, df_knn_imputed_categorical_columns], axis=1, sort=False)\n",
    "df_new = df_new[data.columns]\n",
    "\n",
    "#Converting each column's data type into the most appropriate one\n",
    "df_new = df_new.convert_dtypes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 759 ms, sys: 196 ms, total: 956 ms\n",
      "Wall time: 959 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srinivas/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#One Hot Encoding each of the categorical types\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "df_encoded = df_new.iloc[:,:-1]\n",
    "encoding_info = {}#stores the individual column's transformational models so that it can be inversed later\n",
    "\n",
    "# creating instance of one-hot-encoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "#One Hot encode the categorical features and join with the dataframe\n",
    "for i in df_encoded.columns[df_encoded.dtypes=='string']:\n",
    "    enc_df = pd.DataFrame(enc.fit_transform(df_new[[i]]).toarray())\n",
    "    df_encoded = df_encoded.join(enc_df,how = 'left', lsuffix = '_left', rsuffix = '_right')\n",
    "    encoding_info[i]=enc_df\n",
    "df_encoded = df_encoded.select_dtypes(exclude=['string'])\n",
    "\n",
    "#Label Encodeing for target feature\n",
    "le = preprocessing.LabelEncoder()\n",
    "df_encoded['Rain_Tomorrow'] = le.fit_transform(df_new.iloc[:,-1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 44.8 s, sys: 8.38 s, total: 53.2 s\n",
      "Wall time: 41.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_outlied = df_encoded\n",
    "X = df_outlied\n",
    "#Performing Isolation Forest algorithm for 2% outlier elimination\n",
    "clf = IsolationForest(contamination = 0.02,n_jobs=-1)\n",
    "clf.fit(X)\n",
    "results = clf.predict(X)\n",
    "outliers = X[results == -1]\n",
    "normal = X[results == 1]\n",
    "df_outlied = pd.DataFrame(normal,columns = list(df_outlied.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data for training and testing\n",
    "X,y = df_outlied.iloc[:,:-1], df_outlied.iloc[:,-1:]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.05 s, sys: 440 ms, total: 1.49 s\n",
      "Wall time: 1.48 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Performing Min Max scaling of the data\n",
    "scaler = MinMaxScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imbalance ratio '0':all is 0.7863350293148856\n",
      "Elapsed time: 169.81941986083984\n",
      "Before SMOTE Over Sampling: Rain_Tomorrow\n",
      "0                87737\n",
      "1                23742\n",
      "dtype: int64 \n",
      "\n",
      "\n",
      "After SMOTE Over Sampling: Rain_Tomorrow\n",
      "1                87737\n",
      "0                87737\n",
      "dtype: int64 \n",
      "\n",
      "\n",
      "CPU times: user 2min 49s, sys: 0 ns, total: 2min 49s\n",
      "Wall time: 2min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Checking the imbalance ratio of 0\n",
    "imbalance = y[y==0].count()\n",
    "print(\"Imbalance ratio '0':all is\",imbalance[0]/y.count()[0])\n",
    "\n",
    "#Handling imbalance using oversampling - SMOTE\n",
    "smote = SMOTE(n_jobs=-1)\n",
    "start = time()\n",
    "X_res, y_res = smote.fit_resample(X_train, y_train)\n",
    "print(\"Elapsed time:\",time()-start)\n",
    "print(\"Before SMOTE Over Sampling:\",y_train.value_counts(),'\\n\\n')\n",
    "print(\"After SMOTE Over Sampling:\",y_res.value_counts(),'\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#function to test out the selected and tuned ML algorithms with given dataset\n",
    "X_train,y_train = np.array(X_res),np.array(y_res).reshape(-1,)\n",
    "X_test,y_test = np.array(X_test),np.array(y_test).reshape(-1,)\n",
    "def run_models(X_train,y_train,X_test,y_test):\n",
    "    QDA_best_params = {'reg_param': 0.001}\n",
    "    LR_best_params = {'C': 10, 'penalty': 'l2'}\n",
    "    ABC_best_params = {'learning_rate': 1.0, 'n_estimators': 500}\n",
    "    Tuned_CLS = [(QuadraticDiscriminantAnalysis(**QDA_best_params),\"Tuned QDA\"),\n",
    "                 (LogisticRegression(**LR_best_params),\"Tuned LR\"),\n",
    "                 (AdaBoostClassifier(**ABC_best_params),\"Tuned AB\")]\n",
    "\n",
    "    for clf,name in Tuned_CLS:\n",
    "        start = time()\n",
    "        print(\"\\n\\n\",name)\n",
    "        clf.fit(X_train,y_train)\n",
    "        y_true, y_pred = y_test, clf.predict(X_test)\n",
    "        print(\"Elapsed time:\", time()-start)\n",
    "        print(classification_report(y_true, y_pred))\n",
    "        print()\n",
    "        score = accuracy_score(y_test,y_pred)\n",
    "        confusionmatrix = confusion_matrix(y_test,y_pred)\n",
    "        print(confusionmatrix,name,score,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Tuned QDA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srinivas/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 4.676492929458618\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.57      0.69     21838\n",
      "           1       0.32      0.75      0.45      6032\n",
      "\n",
      "    accuracy                           0.61     27870\n",
      "   macro avg       0.61      0.66      0.57     27870\n",
      "weighted avg       0.77      0.61      0.64     27870\n",
      "\n",
      "\n",
      "[[12439  9399]\n",
      " [ 1525  4507]] Tuned QDA 0.6080373161105131 \n",
      "\n",
      "\n",
      "\n",
      " Tuned LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srinivas/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 7.721967458724976\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.79      0.85     21838\n",
      "           1       0.50      0.75      0.60      6032\n",
      "\n",
      "    accuracy                           0.78     27870\n",
      "   macro avg       0.71      0.77      0.73     27870\n",
      "weighted avg       0.83      0.78      0.80     27870\n",
      "\n",
      "\n",
      "[[17325  4513]\n",
      " [ 1499  4533]] Tuned LR 0.7842841765339075 \n",
      "\n",
      "\n",
      "\n",
      " Tuned AB\n",
      "Elapsed time: 528.7824823856354\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89     21838\n",
      "           1       0.61      0.60      0.61      6032\n",
      "\n",
      "    accuracy                           0.83     27870\n",
      "   macro avg       0.75      0.75      0.75     27870\n",
      "weighted avg       0.83      0.83      0.83     27870\n",
      "\n",
      "\n",
      "[[19539  2299]\n",
      " [ 2415  3617]] Tuned AB 0.8308575529242913 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Testing Just after SMOTE\n",
    "run_models(X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10 µs, sys: 1e+03 ns, total: 11 µs\n",
      "Wall time: 17.2 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Function to do k-best feature selection on given dataset\n",
    "def select_features(k=10):\n",
    "    print(\"\\n\\nK = \",k)\n",
    "    k_best_fs = SelectKBest(k=k).fit(X_train, y_train)\n",
    "    X_train_featured = k_best_fs.transform(X_train)\n",
    "    X_test_featured = k_best_fs.transform(X_test)\n",
    "    print(\"X_train shape:\",X_train.shape,\"X_train_featured shape\",X_train_featured.shape)\n",
    "    print(\"X_test shape:\",X_test.shape,\"X_test_featured shape\",X_test_featured.shape)\n",
    "    return X_train_featured,y_train,X_test_featured,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "K =  1\n",
      "X_train shape: (175474, 111) X_train_featured shape (175474, 1)\n",
      "X_test shape: (27870, 111) X_test_featured shape (27870, 1)\n",
      "\n",
      "\n",
      " Tuned QDA\n",
      "Elapsed time: 0.0582427978515625\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.69      0.79     21838\n",
      "           1       0.40      0.73      0.52      6032\n",
      "\n",
      "    accuracy                           0.70     27870\n",
      "   macro avg       0.65      0.71      0.65     27870\n",
      "weighted avg       0.79      0.70      0.73     27870\n",
      "\n",
      "\n",
      "[[15167  6671]\n",
      " [ 1626  4406]] Tuned QDA 0.7022963760315751 \n",
      "\n",
      "\n",
      "\n",
      " Tuned LR\n",
      "Elapsed time: 0.31101274490356445\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.71      0.80     21838\n",
      "           1       0.41      0.71      0.52      6032\n",
      "\n",
      "    accuracy                           0.71     27870\n",
      "   macro avg       0.65      0.71      0.66     27870\n",
      "weighted avg       0.79      0.71      0.74     27870\n",
      "\n",
      "\n",
      "[[15586  6252]\n",
      " [ 1727  4305]] Tuned LR 0.7137064944384643 \n",
      "\n",
      "\n",
      "\n",
      " Tuned AB\n",
      "Elapsed time: 67.26066756248474\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.84      0.86     21838\n",
      "           1       0.50      0.58      0.54      6032\n",
      "\n",
      "    accuracy                           0.78     27870\n",
      "   macro avg       0.69      0.71      0.70     27870\n",
      "weighted avg       0.80      0.78      0.79     27870\n",
      "\n",
      "\n",
      "[[18278  3560]\n",
      " [ 2526  3506]] Tuned AB 0.7816289917473986 \n",
      "\n",
      "\n",
      "\n",
      "K =  5\n",
      "X_train shape: (175474, 111) X_train_featured shape (175474, 5)\n",
      "X_test shape: (27870, 111) X_test_featured shape (27870, 5)\n",
      "\n",
      "\n",
      " Tuned QDA\n",
      "Elapsed time: 0.14845681190490723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srinivas/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.74      0.82     21838\n",
      "           1       0.44      0.73      0.55      6032\n",
      "\n",
      "    accuracy                           0.74     27870\n",
      "   macro avg       0.67      0.73      0.68     27870\n",
      "weighted avg       0.81      0.74      0.76     27870\n",
      "\n",
      "\n",
      "[[16193  5645]\n",
      " [ 1639  4393]] Tuned QDA 0.738643702906351 \n",
      "\n",
      "\n",
      "\n",
      " Tuned LR\n",
      "Elapsed time: 0.8497419357299805\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.75      0.83     21838\n",
      "           1       0.45      0.73      0.56      6032\n",
      "\n",
      "    accuracy                           0.75     27870\n",
      "   macro avg       0.68      0.74      0.69     27870\n",
      "weighted avg       0.81      0.75      0.77     27870\n",
      "\n",
      "\n",
      "[[16487  5351]\n",
      " [ 1623  4409]] Tuned LR 0.7497667743092932 \n",
      "\n",
      "\n",
      "\n",
      " Tuned AB\n",
      "Elapsed time: 52.58892750740051\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.80      0.85     21838\n",
      "           1       0.48      0.67      0.56      6032\n",
      "\n",
      "    accuracy                           0.77     27870\n",
      "   macro avg       0.69      0.74      0.70     27870\n",
      "weighted avg       0.81      0.77      0.79     27870\n",
      "\n",
      "\n",
      "[[17522  4316]\n",
      " [ 2004  4028]] Tuned AB 0.7732328668819519 \n",
      "\n",
      "\n",
      "\n",
      "K =  10\n",
      "X_train shape: (175474, 111) X_train_featured shape (175474, 10)\n",
      "X_test shape: (27870, 111) X_test_featured shape (27870, 10)\n",
      "\n",
      "\n",
      " Tuned QDA\n",
      "Elapsed time: 0.08993983268737793\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.79      0.85     21838\n",
      "           1       0.49      0.71      0.58      6032\n",
      "\n",
      "    accuracy                           0.77     27870\n",
      "   macro avg       0.70      0.75      0.71     27870\n",
      "weighted avg       0.82      0.77      0.79     27870\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srinivas/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17336  4502]\n",
      " [ 1770  4262]] Tuned QDA 0.7749551489056333 \n",
      "\n",
      "\n",
      "\n",
      " Tuned LR\n",
      "Elapsed time: 2.2748842239379883\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.78      0.84     21838\n",
      "           1       0.48      0.74      0.58      6032\n",
      "\n",
      "    accuracy                           0.77     27870\n",
      "   macro avg       0.70      0.76      0.71     27870\n",
      "weighted avg       0.82      0.77      0.79     27870\n",
      "\n",
      "\n",
      "[[17051  4787]\n",
      " [ 1561  4471]] Tuned LR 0.7722282023681378 \n",
      "\n",
      "\n",
      "\n",
      " Tuned AB\n",
      "Elapsed time: 77.49974370002747\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.87      0.88     21838\n",
      "           1       0.57      0.63      0.60      6032\n",
      "\n",
      "    accuracy                           0.82     27870\n",
      "   macro avg       0.73      0.75      0.74     27870\n",
      "weighted avg       0.82      0.82      0.82     27870\n",
      "\n",
      "\n",
      "[[18959  2879]\n",
      " [ 2235  3797]] Tuned AB 0.8165052027269465 \n",
      "\n",
      "\n",
      "\n",
      "K =  20\n",
      "X_train shape: (175474, 111) X_train_featured shape (175474, 20)\n",
      "X_test shape: (27870, 111) X_test_featured shape (27870, 20)\n",
      "\n",
      "\n",
      " Tuned QDA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srinivas/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 0.25484490394592285\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.48      0.63     21838\n",
      "           1       0.31      0.86      0.46      6032\n",
      "\n",
      "    accuracy                           0.56     27870\n",
      "   macro avg       0.62      0.67      0.55     27870\n",
      "weighted avg       0.79      0.56      0.59     27870\n",
      "\n",
      "\n",
      "[[10444 11394]\n",
      " [  831  5201]] Tuned QDA 0.5613562970936491 \n",
      "\n",
      "\n",
      "\n",
      " Tuned LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srinivas/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 2.388089656829834\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.79      0.85     21838\n",
      "           1       0.49      0.74      0.59      6032\n",
      "\n",
      "    accuracy                           0.78     27870\n",
      "   macro avg       0.70      0.76      0.72     27870\n",
      "weighted avg       0.82      0.78      0.79     27870\n",
      "\n",
      "\n",
      "[[17145  4693]\n",
      " [ 1545  4487]] Tuned LR 0.7761750986724076 \n",
      "\n",
      "\n",
      "\n",
      " Tuned AB\n",
      "Elapsed time: 82.05676913261414\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89     21838\n",
      "           1       0.60      0.58      0.59      6032\n",
      "\n",
      "    accuracy                           0.83     27870\n",
      "   macro avg       0.74      0.74      0.74     27870\n",
      "weighted avg       0.82      0.83      0.83     27870\n",
      "\n",
      "\n",
      "[[19511  2327]\n",
      " [ 2508  3524]] Tuned AB 0.8265159669895945 \n",
      "\n",
      "\n",
      "\n",
      "K =  50\n",
      "X_train shape: (175474, 111) X_train_featured shape (175474, 50)\n",
      "X_test shape: (27870, 111) X_test_featured shape (27870, 50)\n",
      "\n",
      "\n",
      " Tuned QDA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srinivas/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 0.6908657550811768\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.47      0.61     21838\n",
      "           1       0.29      0.79      0.43      6032\n",
      "\n",
      "    accuracy                           0.54     27870\n",
      "   macro avg       0.59      0.63      0.52     27870\n",
      "weighted avg       0.76      0.54      0.57     27870\n",
      "\n",
      "\n",
      "[[10235 11603]\n",
      " [ 1269  4763]] Tuned QDA 0.5381413706494439 \n",
      "\n",
      "\n",
      "\n",
      " Tuned LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srinivas/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 2.8129236698150635\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.79      0.85     21838\n",
      "           1       0.49      0.75      0.59      6032\n",
      "\n",
      "    accuracy                           0.78     27870\n",
      "   macro avg       0.70      0.77      0.72     27870\n",
      "weighted avg       0.83      0.78      0.79     27870\n",
      "\n",
      "\n",
      "[[17174  4664]\n",
      " [ 1535  4497]] Tuned LR 0.7775744528166487 \n",
      "\n",
      "\n",
      "\n",
      " Tuned AB\n",
      "Elapsed time: 98.09155488014221\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89     21838\n",
      "           1       0.60      0.59      0.60      6032\n",
      "\n",
      "    accuracy                           0.83     27870\n",
      "   macro avg       0.75      0.74      0.74     27870\n",
      "weighted avg       0.83      0.83      0.83     27870\n",
      "\n",
      "\n",
      "[[19507  2331]\n",
      " [ 2484  3548]] Tuned AB 0.8272335844994618 \n",
      "\n",
      "\n",
      "\n",
      "K =  100\n",
      "X_train shape: (175474, 111) X_train_featured shape (175474, 100)\n",
      "X_test shape: (27870, 111) X_test_featured shape (27870, 100)\n",
      "\n",
      "\n",
      " Tuned QDA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srinivas/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 2.381138324737549\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.56      0.68     21838\n",
      "           1       0.32      0.75      0.45      6032\n",
      "\n",
      "    accuracy                           0.60     27870\n",
      "   macro avg       0.60      0.65      0.57     27870\n",
      "weighted avg       0.77      0.60      0.63     27870\n",
      "\n",
      "\n",
      "[[12153  9685]\n",
      " [ 1518  4514]] Tuned QDA 0.5980265518478651 \n",
      "\n",
      "\n",
      "\n",
      " Tuned LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srinivas/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 3.3500680923461914\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.79      0.85     21838\n",
      "           1       0.50      0.75      0.60      6032\n",
      "\n",
      "    accuracy                           0.78     27870\n",
      "   macro avg       0.71      0.77      0.73     27870\n",
      "weighted avg       0.83      0.78      0.80     27870\n",
      "\n",
      "\n",
      "[[17304  4534]\n",
      " [ 1496  4536]] Tuned LR 0.7836383207750269 \n",
      "\n",
      "\n",
      "\n",
      " Tuned AB\n",
      "Elapsed time: 139.05390453338623\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.90      0.89     21838\n",
      "           1       0.61      0.60      0.61      6032\n",
      "\n",
      "    accuracy                           0.83     27870\n",
      "   macro avg       0.75      0.75      0.75     27870\n",
      "weighted avg       0.83      0.83      0.83     27870\n",
      "\n",
      "\n",
      "[[19547  2291]\n",
      " [ 2396  3636]] Tuned AB 0.8318263365626122 \n",
      "\n",
      "CPU times: user 10min 20s, sys: 1min 5s, total: 11min 26s\n",
      "Wall time: 8min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Testing out a range of number of features\n",
    "for i in [1,5,10,20,50,100]:\n",
    "    run_models(*select_features(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From the above we discover that k=10 is the best balance in-between accuracy and temporal cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "K =  10\n",
      "X_train shape: (175474, 111) X_train_featured shape (175474, 10)\n",
      "X_test shape: (27870, 111) X_test_featured shape (27870, 10)\n",
      "\n",
      "\n",
      " Tuned QDA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srinivas/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 0.07977771759033203\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.79      0.85     21838\n",
      "           1       0.49      0.71      0.58      6032\n",
      "\n",
      "    accuracy                           0.77     27870\n",
      "   macro avg       0.70      0.75      0.71     27870\n",
      "weighted avg       0.82      0.77      0.79     27870\n",
      "\n",
      "\n",
      "[[17336  4502]\n",
      " [ 1770  4262]] Tuned QDA 0.7749551489056333 \n",
      "\n",
      "\n",
      "\n",
      " Tuned LR\n",
      "Elapsed time: 2.4172635078430176\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.78      0.84     21838\n",
      "           1       0.48      0.74      0.58      6032\n",
      "\n",
      "    accuracy                           0.77     27870\n",
      "   macro avg       0.70      0.76      0.71     27870\n",
      "weighted avg       0.82      0.77      0.79     27870\n",
      "\n",
      "\n",
      "[[17051  4787]\n",
      " [ 1561  4471]] Tuned LR 0.7722282023681378 \n",
      "\n",
      "\n",
      "\n",
      " Tuned AB\n",
      "Elapsed time: 60.113999128341675\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.87      0.88     21838\n",
      "           1       0.57      0.63      0.60      6032\n",
      "\n",
      "    accuracy                           0.82     27870\n",
      "   macro avg       0.73      0.75      0.74     27870\n",
      "weighted avg       0.82      0.82      0.82     27870\n",
      "\n",
      "\n",
      "[[18959  2879]\n",
      " [ 2235  3797]] Tuned AB 0.8165052027269465 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Run the best configuration\n",
    "run_models(*select_features(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(142193, 18)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape #Data before encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(142193, 112)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_encoded.shape # data after one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
