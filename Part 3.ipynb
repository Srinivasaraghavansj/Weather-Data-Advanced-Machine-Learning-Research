{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***PART 1***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer,IterativeImputer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from multiprocessing import Process\n",
    "from time import time\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the data and removing unwanted columns specified below\n",
    "df = pd.read_csv('weatherAUS.csv')#,nrows=10000)\n",
    "df = df.drop(df.columns[0],axis = 1)#Dropping the Dates\n",
    "df = df.drop(df.columns[-2], axis = 1)#Dropping the RISK_MM column\n",
    "data = df.copy()\n",
    "df_2 = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Any features with more than 30% of empty data are removed\n",
    "limitPer = len(df_2) * .7\n",
    "df_2 = df_2.dropna(thresh=limitPer,axis=1)\n",
    "df_3 = df_2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 17s, sys: 465 ms, total: 1min 18s\n",
      "Wall time: 1min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Label Encoding each of the categorical types\n",
    "df_2 = df_2.convert_dtypes()\n",
    "df_encoded = df_2.copy()###########################\n",
    "encoding_info = {}#stores the individual column's transformational models so that it can be inversed later\n",
    "le = preprocessing.LabelEncoder()\n",
    "for i in df_encoded.columns[df_encoded.dtypes=='string']:\n",
    "    fit_by = pd.Series([j for j in df_2.loc[:,i] if isinstance(j,str)])\n",
    "    le.fit(fit_by)\n",
    "    encoding_info[i]=le\n",
    "    df_encoded[i] = fit_by.apply(lambda x: le.transform([x])[0] if type(x) == str else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9min 41s, sys: 4min 23s, total: 14min 5s\n",
      "Wall time: 7min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Performing imputation on missing values\n",
    "imp1 = KNNImputer()\n",
    "df_knn_imputed_float_columns = imp1.fit_transform(df_encoded)\n",
    "df_knn_imputed_float_columns = pd.DataFrame(df_knn_imputed_float_columns, columns = list(df_2.columns))\n",
    "df_new = df_knn_imputed_float_columns\n",
    "\n",
    "##Converting the imputed continuous data back into catagorical by rounding them\n",
    "for i in encoding_info.keys():\n",
    "    df_new[i] = np.round(df_new[i].values,0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.6 s, sys: 241 ms, total: 10.8 s\n",
      "Wall time: 8.42 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_outlied = df_new.copy()\n",
    "X = df_outlied\n",
    "#Performing Isolation Forest algorithm for 2% outlier elimination\n",
    "clf = IsolationForest(contamination = 0.02,n_jobs=-1)\n",
    "clf.fit(X)\n",
    "results = clf.predict(X)\n",
    "outliers = X[results == -1]\n",
    "normal = X[results == 1]\n",
    "df_outlied = pd.DataFrame(normal,columns = list(df_outlied.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.8 ms, sys: 0 ns, total: 20.8 ms\n",
      "Wall time: 19.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Splitting the data for training and testing\n",
    "X,y = df_outlied.iloc[:,:-1], df_outlied.iloc[:,-1:]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 34.5 ms, sys: 0 ns, total: 34.5 ms\n",
      "Wall time: 32.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Performing Min Max scaling of the data\n",
    "scaler = MinMaxScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imbalance ratio '0':all is 0.7862632670489204\n",
      "Elapsed time: 16.38613796234131\n",
      "Before Tomek Under Sampling: RainTomorrow\n",
      "0               87617\n",
      "1               23862\n",
      "dtype: int64 \n",
      "\n",
      "\n",
      "After Tomek Under Sampling: RainTomorrow\n",
      "0               82556\n",
      "1               23862\n",
      "dtype: int64 \n",
      "\n",
      "\n",
      "CPU times: user 2min 54s, sys: 345 ms, total: 2min 54s\n",
      "Wall time: 16.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Checking the imbalance ratio of 0\n",
    "imbalance = y[y==0].count()\n",
    "print(\"Imbalance ratio '0':all is\",imbalance[0]/y.count()[0])\n",
    "\n",
    "#Handling imbalance using undersampling - Tomek Links\n",
    "tl = TomekLinks(n_jobs=-1)\n",
    "start = time()\n",
    "X_res, y_res = tl.fit_resample(X_train, y_train)\n",
    "print(\"Elapsed time:\",time()-start)\n",
    "print(\"Before Tomek Under Sampling:\",y_train.value_counts(),'\\n\\n')\n",
    "print(\"After Tomek Under Sampling:\",y_res.value_counts(),'\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#function to test out the selected and tuned ML algorithms with given dataset\n",
    "X_train,y_train = np.array(X_res),np.array(y_res).reshape(-1,)\n",
    "X_test,y_test = np.array(X_test),np.array(y_test).reshape(-1,)\n",
    "def run_models(X_train,y_train,X_test,y_test):\n",
    "    QDA_best_params = {'reg_param': 0.001}\n",
    "    LR_best_params = {'C': 10, 'penalty': 'l2'}\n",
    "    ABC_best_params = {'learning_rate': 1.0, 'n_estimators': 500}\n",
    "    Tuned_CLS = [(QuadraticDiscriminantAnalysis(**QDA_best_params),\"Tuned QDA\"),\n",
    "                 (LogisticRegression(**LR_best_params),\"Tuned LR\"),\n",
    "                 (AdaBoostClassifier(**ABC_best_params),\"Tuned AB\")]\n",
    "\n",
    "    for clf,name in Tuned_CLS:\n",
    "        start = time()\n",
    "        print(\"\\n\\n\",name)\n",
    "        clf.fit(X_train,y_train)\n",
    "        y_true, y_pred = y_test, clf.predict(X_test)\n",
    "        print(\"Elapsed time:\", time()-start)\n",
    "        print(classification_report(y_true, y_pred))\n",
    "        print()\n",
    "        confusionmatrix = confusion_matrix(y_test,y_pred)\n",
    "        score = accuracy_score(y_test,y_pred)\n",
    "        print()\n",
    "        print(confusionmatrix,name,score,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Tuned QDA\n",
      "Elapsed time: 0.14851927757263184\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90     21948\n",
      "           1       0.65      0.46      0.54      5922\n",
      "\n",
      "    accuracy                           0.83     27870\n",
      "   macro avg       0.76      0.70      0.72     27870\n",
      "weighted avg       0.82      0.83      0.82     27870\n",
      "\n",
      "\n",
      "\n",
      "[[20487  1461]\n",
      " [ 3181  2741]] Tuned QDA 0.8334409759598134 \n",
      "\n",
      "\n",
      "\n",
      " Tuned LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srinivas/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 2.2076144218444824\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.94      0.90     21948\n",
      "           1       0.67      0.49      0.56      5922\n",
      "\n",
      "    accuracy                           0.84     27870\n",
      "   macro avg       0.77      0.71      0.73     27870\n",
      "weighted avg       0.83      0.84      0.83     27870\n",
      "\n",
      "\n",
      "\n",
      "[[20550  1398]\n",
      " [ 3044  2878]] Tuned LR 0.8406171510584858 \n",
      "\n",
      "\n",
      "\n",
      " Tuned AB\n",
      "Elapsed time: 98.28537440299988\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91     21948\n",
      "           1       0.69      0.51      0.59      5922\n",
      "\n",
      "    accuracy                           0.85     27870\n",
      "   macro avg       0.78      0.73      0.75     27870\n",
      "weighted avg       0.84      0.85      0.84     27870\n",
      "\n",
      "\n",
      "\n",
      "[[20592  1356]\n",
      " [ 2888  3034]] Tuned AB 0.8477215644061715 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Run ML just after Tomek links\n",
    "run_models(X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7 µs, sys: 2 µs, total: 9 µs\n",
      "Wall time: 15.3 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Function to do k-best feature selection on given dataset\n",
    "def select_features(k=10):\n",
    "    print(\"\\n\\nK = \",k)\n",
    "    k_best_fs = SelectKBest(k=k).fit(X_train, y_train)\n",
    "    X_train_featured = k_best_fs.transform(X_train)\n",
    "    X_test_featured = k_best_fs.transform(X_test)\n",
    "    print(\"X_train shape:\",X_train.shape,\"X_train_featured shape\",X_train_featured.shape)\n",
    "    print(\"X_test shape:\",X_test.shape,\"X_test_featured shape\",X_test_featured.shape)\n",
    "    return X_train_featured,y_train,X_test_featured,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 0 ns, total: 5 µs\n",
      "Wall time: 9.78 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# for i in [1,5,10,20,50,100]:\n",
    "#     run_models(*select_features(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From the above we discover that k=10 is the best balance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "K =  10\n",
      "X_train shape: (106418, 17) X_train_featured shape (106418, 10)\n",
      "X_test shape: (27870, 17) X_test_featured shape (27870, 10)\n",
      "\n",
      "\n",
      " Tuned QDA\n",
      "Elapsed time: 0.20652151107788086\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.94      0.90     21948\n",
      "           1       0.67      0.45      0.54      5922\n",
      "\n",
      "    accuracy                           0.84     27870\n",
      "   macro avg       0.77      0.69      0.72     27870\n",
      "weighted avg       0.82      0.84      0.82     27870\n",
      "\n",
      "\n",
      "\n",
      "[[20626  1322]\n",
      " [ 3266  2656]] Tuned QDA 0.835378543236455 \n",
      "\n",
      "\n",
      "\n",
      " Tuned LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srinivas/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 3.2776601314544678\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.94      0.90     21948\n",
      "           1       0.68      0.49      0.57      5922\n",
      "\n",
      "    accuracy                           0.84     27870\n",
      "   macro avg       0.77      0.71      0.73     27870\n",
      "weighted avg       0.83      0.84      0.83     27870\n",
      "\n",
      "\n",
      "\n",
      "[[20566  1382]\n",
      " [ 3043  2879]] Tuned LR 0.841227125941873 \n",
      "\n",
      "\n",
      "\n",
      " Tuned AB\n",
      "Elapsed time: 105.02947926521301\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91     21948\n",
      "           1       0.69      0.50      0.58      5922\n",
      "\n",
      "    accuracy                           0.85     27870\n",
      "   macro avg       0.78      0.72      0.74     27870\n",
      "weighted avg       0.84      0.85      0.84     27870\n",
      "\n",
      "\n",
      "\n",
      "[[20595  1353]\n",
      " [ 2941  2981]] Tuned AB 0.8459275206315034 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Run the best configuration\n",
    "run_models(*select_features(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Own function that does robust KNN imputation for both categorical and numerical features\n",
    "def knn_own_imputer(dat):\n",
    "    #to convert the given data into a pandas DataFrame\n",
    "    if isinstance(dat,pd.core.frame.DataFrame):\n",
    "        df_2 = dat\n",
    "    else:\n",
    "        df_2 = pd.DataFrame(dat)\n",
    "    #To print the number of empty values\n",
    "    try:\n",
    "        init_null = df_2.isnull().sum()\n",
    "        print(\"NULL Value report of input:\", init_null)\n",
    "    except:\n",
    "        pass\n",
    "    #dataframes being converted in to appropriate data types\n",
    "    df_2 = df_2.convert_dtypes()\n",
    "    df_encoded = df_2.copy()\n",
    "    encoding_info = {}#stores the individual column's transformational models so that it can be inversed later\n",
    "    encoding_info_classes = {}#stores the individual column's encoding details\n",
    "    #Loading the label encoder\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    #Encoding the catagorical features excluding the empty values\n",
    "    for i in df_encoded.columns[df_encoded.dtypes=='string']:\n",
    "        fit_by = pd.Series([j for j in df_2.loc[:,i] if isinstance(j,str)])\n",
    "        le.fit(fit_by)\n",
    "        encoding_info[i]=le\n",
    "        encoding_info_classes[i] = le.classes_\n",
    "        df_encoded[i] = fit_by.apply(lambda x: le.transform([x])[0] if type(x) == str else x)\n",
    "    #KNN Imputing the empty values\n",
    "    imp1 = KNNImputer()\n",
    "    df_knn_imputed_float_columns = imp1.fit_transform(df_encoded)\n",
    "    df_knn_imputed_float_columns = pd.DataFrame(df_knn_imputed_float_columns, columns = list(df_2.columns))\n",
    "    df_new = df_knn_imputed_float_columns\n",
    "    #Function to match a value to the closest value in the list\n",
    "    def closest(lst, K): \n",
    "        return lst[min(range(len(lst)), key = lambda i: abs(lst[i]-K))] \n",
    "    #Converting the imputed continuous data back into catagorical by rounding them\n",
    "    for i in encoding_info.keys():\n",
    "        df_new[i] = np.round(df_new[i].values,0).astype(int)\n",
    "    #Matching the rounded values to the closest available classes and decoding them\n",
    "    for i in encoding_info_classes.keys():\n",
    "        encoding_info[i].classes_ = encoding_info_classes[i]\n",
    "        df_new[i] = df_new[i].apply(lambda x: encoding_info[i]\\\n",
    "                .inverse_transform([x])[0] if x in np.arange(len(encoding_info[i].classes_))\\\n",
    "                                    else closest(np.arange(len(encoding_info[i].classes_)),x))    \n",
    "    \n",
    "    #To print the number of empty values\n",
    "    try:\n",
    "        final_null = df_new.isnull().sum()\n",
    "        print(\"\\n\\nNULL Value report of input:\", final_null)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NULL Value report of input: Location           0\n",
      "MinTemp            5\n",
      "MaxTemp            1\n",
      "Rainfall          10\n",
      "WindGustDir        3\n",
      "WindGustSpeed      3\n",
      "WindDir9am       197\n",
      "WindDir3pm        22\n",
      "WindSpeed9am       3\n",
      "WindSpeed3pm       3\n",
      "Humidity9am        0\n",
      "Humidity3pm        0\n",
      "Pressure9am        0\n",
      "Pressure3pm        0\n",
      "Temp9am            0\n",
      "Temp3pm            0\n",
      "RainToday         10\n",
      "RainTomorrow       0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "NULL Value report of input: Location         0\n",
      "MinTemp          0\n",
      "MaxTemp          0\n",
      "Rainfall         0\n",
      "WindGustDir      0\n",
      "WindGustSpeed    0\n",
      "WindDir9am       0\n",
      "WindDir3pm       0\n",
      "WindSpeed9am     0\n",
      "WindSpeed3pm     0\n",
      "Humidity9am      0\n",
      "Humidity3pm      0\n",
      "Pressure9am      0\n",
      "Pressure3pm      0\n",
      "Temp9am          0\n",
      "Temp3pm          0\n",
      "RainToday        0\n",
      "RainTomorrow     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Testing out our function with sample 1000 values\n",
    "a = knn_own_imputer(df_3.iloc[:1000,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location</th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>WindGustDir</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindDir9am</th>\n",
       "      <th>WindDir3pm</th>\n",
       "      <th>WindSpeed9am</th>\n",
       "      <th>WindSpeed3pm</th>\n",
       "      <th>Humidity9am</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>Pressure9am</th>\n",
       "      <th>Pressure3pm</th>\n",
       "      <th>Temp9am</th>\n",
       "      <th>Temp3pm</th>\n",
       "      <th>RainToday</th>\n",
       "      <th>RainTomorrow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Albury</td>\n",
       "      <td>13.4</td>\n",
       "      <td>22.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>W</td>\n",
       "      <td>44.0</td>\n",
       "      <td>W</td>\n",
       "      <td>WNW</td>\n",
       "      <td>20.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1007.7</td>\n",
       "      <td>1007.1</td>\n",
       "      <td>16.9</td>\n",
       "      <td>21.8</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albury</td>\n",
       "      <td>7.4</td>\n",
       "      <td>25.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>WNW</td>\n",
       "      <td>44.0</td>\n",
       "      <td>NNW</td>\n",
       "      <td>WSW</td>\n",
       "      <td>4.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1010.6</td>\n",
       "      <td>1007.8</td>\n",
       "      <td>17.2</td>\n",
       "      <td>24.3</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Albury</td>\n",
       "      <td>12.9</td>\n",
       "      <td>25.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>WSW</td>\n",
       "      <td>46.0</td>\n",
       "      <td>W</td>\n",
       "      <td>WSW</td>\n",
       "      <td>19.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1007.6</td>\n",
       "      <td>1008.7</td>\n",
       "      <td>21.0</td>\n",
       "      <td>23.2</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Albury</td>\n",
       "      <td>9.2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NE</td>\n",
       "      <td>24.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>E</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1017.6</td>\n",
       "      <td>1012.8</td>\n",
       "      <td>18.1</td>\n",
       "      <td>26.5</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Albury</td>\n",
       "      <td>17.5</td>\n",
       "      <td>32.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>W</td>\n",
       "      <td>41.0</td>\n",
       "      <td>ENE</td>\n",
       "      <td>NW</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1010.8</td>\n",
       "      <td>1006.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>29.7</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Albury</td>\n",
       "      <td>5.6</td>\n",
       "      <td>17.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>WSW</td>\n",
       "      <td>19.0</td>\n",
       "      <td>S</td>\n",
       "      <td>SSE</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1020.5</td>\n",
       "      <td>1016.4</td>\n",
       "      <td>10.2</td>\n",
       "      <td>17.4</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Albury</td>\n",
       "      <td>10.2</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>WSW</td>\n",
       "      <td>13.0</td>\n",
       "      <td>SSW</td>\n",
       "      <td>SE</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1014.8</td>\n",
       "      <td>1012.6</td>\n",
       "      <td>13.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Albury</td>\n",
       "      <td>11.1</td>\n",
       "      <td>21.4</td>\n",
       "      <td>4.2</td>\n",
       "      <td>NW</td>\n",
       "      <td>41.0</td>\n",
       "      <td>NNW</td>\n",
       "      <td>S</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1013.2</td>\n",
       "      <td>1010.1</td>\n",
       "      <td>13.3</td>\n",
       "      <td>19.9</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Albury</td>\n",
       "      <td>8.7</td>\n",
       "      <td>21.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>33.0</td>\n",
       "      <td>S</td>\n",
       "      <td>NNW</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1012.2</td>\n",
       "      <td>1009.5</td>\n",
       "      <td>13.5</td>\n",
       "      <td>21.3</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Albury</td>\n",
       "      <td>10.7</td>\n",
       "      <td>18.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NE</td>\n",
       "      <td>46.0</td>\n",
       "      <td>NNW</td>\n",
       "      <td>S</td>\n",
       "      <td>13.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>1010.1</td>\n",
       "      <td>1007.4</td>\n",
       "      <td>12.6</td>\n",
       "      <td>18.4</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Location  MinTemp  MaxTemp  Rainfall WindGustDir  WindGustSpeed  \\\n",
       "0     Albury     13.4     22.9       0.6           W           44.0   \n",
       "1     Albury      7.4     25.1       0.0         WNW           44.0   \n",
       "2     Albury     12.9     25.7       0.0         WSW           46.0   \n",
       "3     Albury      9.2     28.0       0.0          NE           24.0   \n",
       "4     Albury     17.5     32.3       1.0           W           41.0   \n",
       "..       ...      ...      ...       ...         ...            ...   \n",
       "995   Albury      5.6     17.8       0.0         WSW           19.0   \n",
       "996   Albury     10.2     16.0       0.0         WSW           13.0   \n",
       "997   Albury     11.1     21.4       4.2          NW           41.0   \n",
       "998   Albury      8.7     21.8       0.0          NW           33.0   \n",
       "999   Albury     10.7     18.6       0.0          NE           46.0   \n",
       "\n",
       "    WindDir9am WindDir3pm  WindSpeed9am  WindSpeed3pm  Humidity9am  \\\n",
       "0            W        WNW          20.0          24.0         71.0   \n",
       "1          NNW        WSW           4.0          22.0         44.0   \n",
       "2            W        WSW          19.0          26.0         38.0   \n",
       "3           SE          E          11.0           9.0         45.0   \n",
       "4          ENE         NW           7.0          20.0         82.0   \n",
       "..         ...        ...           ...           ...          ...   \n",
       "995          S        SSE           4.0          13.0         89.0   \n",
       "996        SSW         SE           9.0           4.0         87.0   \n",
       "997        NNW          S           7.0           7.0         88.0   \n",
       "998          S        NNW           4.0          24.0         79.0   \n",
       "999        NNW          S          13.0          28.0         89.0   \n",
       "\n",
       "     Humidity3pm  Pressure9am  Pressure3pm  Temp9am  Temp3pm RainToday  \\\n",
       "0           22.0       1007.7       1007.1     16.9     21.8        No   \n",
       "1           25.0       1010.6       1007.8     17.2     24.3        No   \n",
       "2           30.0       1007.6       1008.7     21.0     23.2        No   \n",
       "3           16.0       1017.6       1012.8     18.1     26.5        No   \n",
       "4           33.0       1010.8       1006.0     17.8     29.7        No   \n",
       "..           ...          ...          ...      ...      ...       ...   \n",
       "995         59.0       1020.5       1016.4     10.2     17.4        No   \n",
       "996         80.0       1014.8       1012.6     13.0     15.0        No   \n",
       "997         53.0       1013.2       1010.1     13.3     19.9        No   \n",
       "998         50.0       1012.2       1009.5     13.5     21.3        No   \n",
       "999         57.0       1010.1       1007.4     12.6     18.4        No   \n",
       "\n",
       "    RainTomorrow  \n",
       "0             No  \n",
       "1             No  \n",
       "2             No  \n",
       "3             No  \n",
       "4             No  \n",
       "..           ...  \n",
       "995           No  \n",
       "996          Yes  \n",
       "997           No  \n",
       "998           No  \n",
       "999          Yes  \n",
       "\n",
       "[1000 rows x 18 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
